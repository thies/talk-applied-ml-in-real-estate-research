<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Thies Lindenthal: Applied ML in Real Estate Research</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/white.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
		<link rel="stylesheet" href="tweaks.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<section data-background-image="imgs/cliff.jpg">
						<h2><span class="transparent70">Applied ML in Real Estate</span></h2>

						<h2><span class="subtitle transparent70">(A picture is worth a thousand words!)</span></h2>

						<h2><span class="subtitle transparent70">Dr. Thies Lindenthal</span></h2>
						<p><span class="subtitle transparent70"> Department of Land Economy / University of Cambridge</span><br>
						<span class="subtitle transparent70">E-mail: htl24@cam.ac.uk / Twitter: @ThiesLindenthal</span></p>
							<p>&nbsp;</p>
							<p>&nbsp;</p>
			</section>

				<section data-markdown >
					<textarea data-template>
						## Walking down a street...<span class="subtitle"><br/>So much to learn from looking at buildings, spaces, people... </span>
						<iframe data-src="https://www.google.com/maps/embed?pb=!4v1615400218848!6m8!1m7!1sfrGO3071bDjlMFWKCuPROg!2m2!1d52.20218228800385!2d0.116240823654906!3f214.30357533449632!4f12.499881249341925!5f0.7820865974627469" data-preload width="900" height="500"></iframe>
						Note:
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Research Agenda<span class="subtitle"><br/>Joint projects with Erik Johnson, Carolin Schmidt & Wayne Wan</span>
						1. How can we use new sensors such as street-level images to learn more about the built environment/individual buildings/investment performance and values?
						2. How can we understand what is happening inside any of the ML models and interpret the findings beyond raw predictive power?
						3. How can ML techniques help us to understand subjective perceptions of buildings, such as aesthetic appeal, uniqueness, or charme?
						Note:
					</textarea>
				</section>
				<section data-background-image="imgs/romsey_road.jpg">
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<h2><span class="darkonlight">Teach computers to “see”</span>
						<span class="subtitle darkonlight"><br />Infer quality or style attributes from street-level images.</span></h2>
				</section>

				<section data-background-image="imgs/romsey_road.jpg">
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>

					<h2><span class="darkonlight">Vintage Value?</span>
						<span class="subtitle darkonlight"><br /><a href="http://www.lindenthal.eu/assets/papers/Lindenthal%20and%20Johnson%20-%202021%20-%20Machine%20Learning,%20Architectural%20Styles%20and%20Property%20Values.pdf">“Machine Learning, Architectural Styles and Property Values”</a>,<br/> with Erik Johnson</span></h2>
				</section>

				<section data-markdown>
					<textarea data-template>
					## Motivation

					* For a while now, the UK Government has been emphasising the "beauty" of homes and neighborhoods.
					* A _Building Better, Building Beautiful Commission_ advises on design choices.
					It's inaugural chairman (Roger Scruton) claimed:
					_"We should then build as our Georgian and Victorian forebears built [...] All objections to new building would slip away in the sheer relief of the public"_.
					* If that were true, we should observe a direct sales premium for buildings built in vernacular styles and an indirect premium for houses surrounded by traditional architecture.
			</textarea>
			</section>

			<section data-markdown>
				<textarea data-template>
				## Approach

				* Automatically classify exterior of homes, merge with transaction data, test for price effects.
				* Existing work at street/neighbourhood level
					- Naik et al.(2017) describe how neighborhood demographics may impact the physical appearance of neighborhoods.
					- Gebru et al. (2017) use vehicle make and model information to predict income, race, education, and voting patterns.
					- Glaeser et al. (2018) predict income in New York City.
					- Naik, Raskar, and Hidalgo (2016) create a neighborhood safety based Streetscore.
					- De Nadai et al. (2016) find that greenery and street-facing windows contribute to a positive appearance of safety.
					- Liu et al. (2017) evaluate the quality and upkeep of the built environment along Beijing’s streets.
				* Building level
					 - Glaeser, Kincaid, and Naik (2018): Improvements in exterior translate into higher sales prices - and vice versa.

				</textarea>
		</section>

				<section class="white" data-background-color="#ffffff">
					<h2>Our Toolbox<span class="subtitle"><br />Computer vision + ML classification + trad. econometrics<br /></span></h2>
					<img src="imgs/research_feature_vectors.png">
				</section>

				<section data-markdown>
					<textarea data-template>
					## Practical challenges<span class="subtitle"><br />Shoot a good picture of the house...</span>

					<img src="imgs/84VineryRd.png" height=500>
					</textarea>
				</section>

				<section>
				<section data-markdown>
					<textarea data-template>
					## Better <span class="subtitle"><br />Just the house</span>

					<img src="imgs/84VineryRoadGoodAim.png" height=500>
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
					## GIS work <span class="subtitle"><br />Viewshed analysis based on Ordnance Survey building maps.</span>

					<img src="imgs/fan.png" height=500>
					</textarea>
				</section>
			</section>

			<section data-markdown data-background-image="imgs/map_romsey.jpeg" >
				<textarea data-template>
					## <span class="darkonlight">Spatial dependence</span><span class="subtitle darkonlight">Classification improves when neighbours are looked at as well.</span>

					* <span class="darkonlight">Styles are not randomly distributed.</span>
					* <span class="darkonlight">How to model spatial dependence in a deep neural network?</span>
					* <span class="darkonlight">Similar to Ghimire, Rogan, and Miller (2010): Stack feature vectors.</span>

				</textarea>
			</section>



				<section data-markdown data-background-image="imgs/fake_victorian.jpg" >
					<textarea data-template>
						<p>&nbsp;</p>
						<p>&nbsp;</p>
						<p>&nbsp;</p>
						<p>&nbsp;</p>
						<p>&nbsp;</p>
						<p>&nbsp;</p>
						<p>&nbsp;</p>

						## <span class="darkonlight">Key finding</span><span class="subtitle darkonlight"> (besides proof of concept)</span>

						* <span class="darkonlight">No price premium for NEW buildings in traditional styles detectable.</span>
					</textarea>
				</section>


				<section data-background-image="imgs/styles_uk.png">
					<h2><span class="darkonlight">Large scale, low cost</span><span class="subtitle darkonlight"><br />Collecting images/feature vectors of each building in the UK.</span></h2>
				</section>


				<section data-background-image="imgs/romsey_road_1.jpg">
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>

					<h2><span class="darkonlight">Electric car!</span>
						<span class="subtitle darkonlight"><br /></span></h2>
				</section>

				<section data-background-image="imgs/romsey_road_2.jpg">
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>

					<h2><span class="darkonlight">Solar panels!</span>
						<span class="subtitle darkonlight"><br /></span></h2>
				</section>

				<section data-background-image="imgs/romsey_road_3.jpg">
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>
					<p>&nbsp;</p>

					<h2><span class="darkonlight">Loft conversion!</span>
						<span class="subtitle darkonlight"><br /></span></h2>
				</section>


				<section data-background-image="imgs/beach.jpg">
						<h2><span class="transparent70">Questions so far?</span></h2>
						<br>
						<h3><span class="transparent70">Don't be shy.</span></h3>
							<p>&nbsp;</p>
							<p>&nbsp;</p>
			</section>


				<section data-markdown >
					<textarea data-template>
						## Accountability Gap<span class="subtitle"><br/>Joint work with Wayne Wan (<a href="https://www.lindenthal.eu/assets/papers/Wan%20and%20Lindenthal%20-%20System%20Testing.pdf">link to paper</a>)</span>

						* If all you need is predictive power then go ahead, increase training data, tweak models...
						* Can we interpret the predicted values? Communicate what is causing an outcome?
							- Automatic valuations / property taxes
							- Causal inference? At least a little bit?
						* How to ensure we are not breaking any laws (and not unethical in the first place)?
							- Discrimination based on protected characteristics is illegal!
							- Mortgage applications, tenant screening, valuations.

					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Amazon failed (I)<span class="subtitle"><br/>If even a tech giant struggles, caution might be warranted...</span>

						<img src="imgs/amazon1.png" height=450>
					</textarea>
				</section>
				<section data-markdown >
					<textarea data-template>
						## Amazon failed (II)<span class="subtitle"><br/>Racist face recognition systems...</span>

						<img src="imgs/amazon2.png" height=450>
					</textarea>
				</section>
				<section data-markdown >
					<textarea data-template>
						## Microsoft failed<span class="subtitle"><br/>Racist chatbot...</span>

						<img src="imgs/microsoft.png" height=450>
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Deliveroo failed<span class="subtitle"><br/>Companies are liable for biased ML systems.</span>
						<img src="imgs/deliveroo.png" height=450>
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Predictive power not good enough!<span class="subtitle"><br/>Transparency and due diligence needed</span>

						* _System testing_ is a concept from software engineering:
							- While developing a system, engineers define tests that check whether the outcome remains in pre-defined range.
						* Training an ML system is software development.
							- Follow best practices, define and implement system tests.
							- Such tests should be independent of the training process.
							- Tests are customised to task at hand. We give two examples.

					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Vintage classification test<span class="subtitle"><br/>Which aspects lead to a classification?</span>

						* Architects told us: Focus on windows, doors, rooflines, ratios, brickwork
						* Test definition: "Good" model should emphasise informative aspects and ignore background, trees, cars, people.
						* Test should be implementable on large sample &ndash; fully automated.
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Relevant objects<span class="subtitle"><br/>Off-the-shelf object detection reveals areas that _should_ matter...</span>
						<img src="imgs/object_detection.jpg" height=450>
					</textarea>
				</section>


				<section data-markdown >
					<textarea data-template>
						## Relevant pixels<span class="subtitle"><br/>LIME algorithm detects areas that matter for classification.</span>

						* Local interpretable model-agnostic explanation algorithm (LIME) identifies "super pixels" (Ribeiro et al., 2016).
							- Alternative approach, SHAP (Shapley Additive Explanation)
						<br/><img src="imgs/Lime_interwar.png" height=350>
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Relevant pixels<span class="subtitle"><br/>Super pixels depend on classification</span>

						* For competing (incorrect) classifications, different sets of super pixels are detected.
						<br/><img src="imgs/Lime_postwar.png" height=350>
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Right emphasis?<span class="subtitle"><br/>Kind of: focus on doors, windows &ndash; but also cars.</span>

						* Score of 1 represents a proportional representation. Low score for trees is good!
						<p><img src="imgs/verification_test_score_1.png" height=400><p>
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Right emphasis?<span class="subtitle"><br/>Kind of: focus on doors, windows &ndash; but also cars.</span>

						* Overall, a consistent pattern across styles. But there is a strange emphasis on cars for Georgian homes.
						<p><img src="imgs/verification_test_score_2.png" height=400><p>
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Is focus good?<span class="subtitle"><br/>Yes, _correct_ classifications emphasise doors, windows _more_...</span>

						* ... but not trees, cars.
						<p><img src="imgs/univariate_test.png" height=400><p>
					</textarea>
				</section>

				<section data-markdown >
					<textarea data-template>
						## New model, new test<span class="subtitle"><br/>Automatic valuation: Shift in focus?</span>

						* Wealth confounding factor for car brands and home values? Externalities?
						<p><img src="imgs/house_cars.jpg" height=400><p>
					</textarea>
				</section>

				<section >
						<h2> ML in AVM<span class="subtitle"><br/>Automatic valuation, incorporating image data.</span></h2>

						<ul>
						<li>$ \small log({Price}_{it}) = \alpha_{0} + X^{'}_{it}\beta + \varphi_t + \omega_i + \epsilon_{it} $</li>
						<li>Classify residuals based on images (out of sample), then re-estimate:</li>
						<li>$ \small log({Price}_{it}) = \alpha_{0} + X^{'}_{it}\beta + PredResidual_i\gamma + \varphi_t + \omega_i + \epsilon_{it} $</li>
						<ul>
						<p><img src="imgs/avm_rmse_mae.png"><p>
				</section>

				<section data-markdown >
					<textarea data-template>
						## Black-box behaviour<span class="subtitle"><br/>Automatic valuation: Shift in focus?</span>

						* More weight on cars! If vintage is explicitly controlled for (3) then loading on windows and doors decreases.
						<p><img src="imgs/avm_verification_test_scores.png" height=400><p>
					</textarea>
				</section>


				<section data-markdown >
					<textarea data-template>
						## What did we learn?<span class="subtitle"><br/>Better understanding of inner workings of ML black boxes.</span>

						* Far from perfect, still, but models behave similarly to human experts.
						* Findings are helpful for improving the classifications.
							- Windows and doors should be visibile on images. No trees!
							- Some segments appear to be problematic: Georgian/cars.
							- We would not have known that without testing. Now we can re-train models &ndash; or be aware of limitations.
					</textarea>
				</section>

				<section data-background-image="imgs/beach.jpg">
						<h2><span class="transparent70">More Questions?</span></h2>
						<br>
						<h3><span class="transparent70">There is surely something.</span></h3>
							<p>&nbsp;</p>
							<p>&nbsp;</p>
			</section>


				<section data-markdown data-background-video="imgs/PXL_20210310_232954432.mp4" data-background-video-loop data-background-video-muted>
					<textarea data-template>
						## <span class="transparent70"> What's next?</span><span class=" transparent70 subtitle"><br/>What is it that people pay attention to when looking at houses?</span>

						* <span class="transparent70">New project with Carolin Schmidt &amp; Wayne Wan</span>
						* <span class="transparent70">Let people like/dislike photos of houses</span>
						* <span class="transparent70">Train an ML model based on personal tastes: Digital twin (sort of).</span>
						* <span class="transparent70">Which features are attractive? Homogeneous tastes?</span>
						* <span class="transparent70">Investigate whether revealed preferences match self-reported preferences.</span>
						* <span class="transparent70">Participate: https://4walls.cremll.com</span>

					</textarea>
				</section>


				<section>
				<section data-markdown>
					<textarea data-template>
						## Incredible diversity<span class="subtitle"><br/>We had expected a bimodal distribution &mdash; but tastes differ a lot!</span>
						<img src="imgs/hist_likes_training_data_many_responses.png" height="500">
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Incredible diversity<span class="subtitle"><br/>Less positive verdicts from people who ranked many images.</span>
						<img src="imgs/hist_likes_training_data_few_responses.png" height="500">
					</textarea>
				</section>

			</section>


				<section data-markdown>
					<textarea data-template>
						## Mostly positive<span class="subtitle"><br/>Greenery, high quality material, historic buildings.</span>
						<img src="imgs/example_like.png" height="500">
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Mostly negative<span class="subtitle"><br/>Neglected, low quality, ad-hoc styles.</span>
						<img src="imgs/example_dislike.png" height="500">
					</textarea>
				</section>
				<section data-markdown>
					<textarea data-template>
						## Mixed responses<span class="subtitle"><br/>These are really interesting: Where do we differ?</span>
						<img src="imgs/example_mixed.png" height="500">
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						## New working paper<span class="subtitle"><br/></span>

						* "Aesthetic Preferences for Residential Architecture: Finding Ground Truth with Machine Learning" ([Link](http://www.lindenthal.eu/assets/papers/Lindenthal,%20Schmidt%20and%20Wan%20-%20Aesthetic%20Preferences%20for%20Residential%20Architecture.pdf))
					</textarea>
				</section>


				<section data-markdown>
					<textarea data-template>
						## Clusters of tastes?<span class="subtitle"><br/>No strong clusters detected.</span>
						<img src="imgs/kmeans.png" height="500">
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						## Still, we can predict taste<span class="subtitle"><br/>Personalised classifiers effectively learn from our swipes.</span>

						<img src="imgs/precision.png">

						* People like trees, dislike density.
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						## Searching ground truth<span class="subtitle"><br/>Participants are not consistent in their rankings.</span>
						* Rankings become more critical in time.
						<img src="imgs/share_likes_in_time.png">
					</textarea>
				</section>

				<section>
				<section data-markdown>
					<textarea data-template>
						## Black box vs. black box<span class="subtitle"><br/></span>
						<img src="imgs/consistency_table.png" height=500>
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						## Negative trend<span class="subtitle"><br/>Significant decline in likes</span>
						<img src="imgs/consistency_table_2.png" height=500>
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						## ML classifiers...<span class="subtitle"><br/>Can explain 2/3 of all likes well...</span>
						<img src="imgs/consistency_table_3.png" height=500>
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						## ML classifications...<span class="subtitle"><br/> Humans are more predictable later. </span>
						<img src="imgs/consistency_table_4.png" height=500>
					</textarea>
				</section>

				<section data-markdown>
					<textarea data-template>
						## Swayed by trees.<span class="subtitle"><br/>But only in beginning. Density effect consistent.</span>
						<img src="imgs/consistency_table_5.png" height=500>
					</textarea>
				</section>
			</section>

			<section data-markdown>
				<textarea data-template>
					## Findings<span class="subtitle"><br/>The real black box: is it between our ears?</span>
					* Personalised classifiers are in reach: They can be trained with limited effort from participant (20 min?)
					* Predictions are not perfect &mdash; but they are consistent.
					* ML helps to understand how we look at the built environment.

					<img src="imgs/icecream.jpg" height=300>

				</textarea>
			</section>


				<section data-background-image="imgs/beach.jpg">
						<h2><span class="transparent70">Let&apos;s talk?</span></h2>
						<h3><span class="transparent70">I would love to hear from you!</span></h3>
						<p><span class="transparent70">E-mail: htl24@cam.ac.uk <br/> Twitter: @ThiesLindenthal</span></p>
							<p>&nbsp;</p>
							<p>&nbsp;</p>
			</section>

			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				math: {
					mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
					config: 'TeX-AMS_HTML-full',
					// pass other options into `MathJax.Hub.Config()`
					TeX: { Macros: { RR: "{\\bf R}" } }
				},
				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
			});
		</script>
	</body>
</html>
